streamlit
langchain_community
langchain
CMAKE_ARGS="-DLLAMA_CUDA=on" pip install llama-cpp-python
